---
title: Simulating and Fitting One Parameter IRT Model
date: |
  | `r Sys.setlocale(locale="en_US.UTF-8"); format(Sys.Date(), "%b %d, %Y")`
output:
  html_document:
    theme: readable
    highlight: tango
    toc: true
    toc_float: 
      collapsed: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	message = FALSE,
	warning = FALSE,
	attr.source = '.numberLines',
	results = 'hold',
	out.width = "50%",
	comment = "",
	fig.dim = c(8, 8)
)
```


## Simulating Data

```{r}
set.seed(10)
library(tidyr)
library(dplyr)

# Helper functions
logistic = function(x) { 1 / (1 + exp(-x)) }
rbernoulli = function(prob) 
  rbinom(n = length(prob), size = 1, prob = prob)

# The logistic function maps real numbers to Probabilities
logistic(-2:2)
x = seq(from = -6, to = 6, by = 0.1)
plot(x, logistic(x))
```

```{r}
# rbernoulli() is a wrapper around the more general binomial random number 
# genrator to create 1 & 0s according to a probability
rbernoulli(c(0, 0.5, 0.5, 1))
rbernoulli(rep(0.75, 10000)) |> mean()  # Replicate 10000 times
```


```{r }
n_item = 20
n_subj = 100
n_resp = n_subj * n_item
```

```{r}
# Simulated data
theta = rnorm(n = n_subj, mean = 0, sd = 1)  # Subjects' ability
delta = rnorm(n = n_item, mean = 0, sd = 1)  # Items' difficulty

d = tibble::tibble(
  subj = rep(1:n_subj, each = n_item), # 1, 1, 1, ..., 1,  2, 2, 2, ..., 2, 
  item = rep(1:n_item, n_subj),        # 1, 2, 3, ..., 10, 1, 2, 3, ..., 10,
  theta = theta[subj],
  delta = delta[item],
  endorse = rbernoulli(prob = logistic(theta - delta))
)
glimpse(d)
```

See notes for another way to create crossed observations with `expand.grid()`[^1].

```{r}
# Wider format to pass to `ltm::rasch()`
d_wide = d %>% 
  dplyr::select(subj, item, endorse) %>%
  pivot_wider(names_from = item, values_from = endorse)
head(d_wide)
```


[^1]:   

    ```{r}
    d2 = expand.grid(seq_along(theta), seq_along(delta))
    colnames(d2) = c("subj", "item")
    d2$theta = theta[d2$subj]
    d2$delta = delta[d2$item]
    d2$endorse = rbernoulli(prob = logistic(d2$theta - d2$delta))
    glimpse(d)
    ```




## Model fitting on simulated data

### Model 1: Rasch Model

```{r }
library(ltm)
irt_rasch = rasch(d_wide[, 2:ncol(d_wide)], IRT.param = T)

# Model parameter estimates
est_difficulty = summary(irt_rasch)$coefficients[1:n_item, 1]
score.dat = factor.scores(irt_rasch)$score.dat
resp_score = score.dat$z1
resp_pat = sapply(seq_along(resp_score), 
                  function(i) paste(score.dat[i, 1:n_item], collapse=""))
get_subj_ability = function(subj_id) {
  resp = paste(d_wide[subj_id, 2:ncol(d_wide)], collapse = "")
  resp_score[resp_pat == resp]
}
est_ability = sapply(1:n_subj, function(id) get_subj_ability(id))
```

```{r}
# Compare estimated with true parameter (item difficulty)
plot(est_difficulty , delta)
abline(a=0, b=1)
text(x = 0.5, y = -0.5, 
     paste("r = ", cor(est_difficulty , delta) |> round(3)))
```


```{r}
# Compare estimated with true parameter (subject ability)
plot(est_ability, theta)
abline(a=0, b=1)
text(x = 1.5, y = -0.5, 
     paste("r = ", cor(est_ability, theta) |> round(3)))
```





### Model 2: GLMM

with subject ability as **random** effects and item difficulty as **fixed** effects

```{r }
library(lme4)

d$subj = factor(d$subj)
d$item = factor(d$item)

# -1 removes intercept in fixed effect
glmm = glmer(endorse ~ -1 + item + (1|subj), data = d, 
             family = binomial(link='logit'))

(m_summ = summary(glmm, cor=F))
fixed_eff = m_summ$coefficients[, 1]
rnd_eff = ranef(glmm)$subj[, 1]
```

```{r}
# Compare estimated with true parameter (item difficulty)
plot(-fixed_eff , delta)
abline(a=0, b=1)
text(x = 0.5, y = -0.5, 
     paste("r = ", cor(-fixed_eff , delta) |> round(3)))
```


```{r}
# Compare estimated with true parameter (subject ability)
plot(rnd_eff, theta)
abline(a=0, b=1)
text(x = 1.5, y = -0.5, 
     paste("r = ", cor(rnd_eff, theta) |> round(3)))
```




## Model Comparison

### Model Estimates

```{r }
plot(est_difficulty, -fixed_eff)
abline(a=0, b=1)
text(x = 1, y = -1,
     paste("r =",   cor(est_difficulty, -fixed_eff), "\n",
           "SSE =", sum((est_difficulty - (-fixed_eff))^2)
           )
     )
```

```{r}

plot(est_ability, rnd_eff)
abline(a=0, b=1)
text(x = 1, y = -1,
     paste("r =", cor(est_difficulty, -fixed_eff), "\n",
           "SSE =", sum((est_ability - rnd_eff)^2)
           )
     )
```



### Distance to True Parameter Values

```{r }
# Mean Squared Error for Item difficulties Estimates
mean((est_difficulty - delta)^2)  # IRT Rasch
mean((-fixed_eff - delta)^2)      # GLMM
```

```{r}
# Mean Squared Error for Subject Abilities Estimates
mean((est_ability - theta)^2)  # IRT Rasch
mean((rnd_eff - theta)^2)      # GLMM
```


## Relationship b/w Raw Test Score and Ability


### Estimated raw scores

$$X = \sum\limits_{item} P(\theta) + \epsilon$$

```{r}
latent2raw = function(ability) {
  raw_scores = sapply(ability, function(theta) {
    probs = logistic(theta - est_difficulty)
    sum(probs)
  })
  return(raw_scores)
}

latent_scores = seq(from=-3, to=3, by=0.01)
est_raw_scores = latent2raw(latent_scores)

m = lm(est_raw_scores ~ latent_scores)
plot(latent_scores, est_raw_scores, type = "l", lty = 1, col="red")
abline(m$coefficients)
```



### Empirical Data

```{r}
raw_scores = apply(d_wide[, -1], MARGIN = 1, 
                   function(row) sum(row))

m = lm(raw_scores ~ est_ability)
plot(est_ability, raw_scores)
abline(m$coefficients)
```


## Estimater Robustness

IRT assumes a normal distribution of subject ability.

```{r}
dgm = function(theta, delta) {
  d = tibble::tibble(
    subj = rep(1:n_subj, each = n_item), # 1, 1, 1, ..., 1,  2, 2, 2, ..., 2, 
    item = rep(1:n_item, n_subj),        # 1, 2, 3, ..., 10, 1, 2, 3, ..., 10,
    theta = theta[subj],
    delta = delta[item],
    endorse = rbernoulli(prob = logistic(theta - delta))
  )
  d_wide = d %>% 
    dplyr::select(subj, item, endorse) %>%
    pivot_wider(names_from = item, values_from = endorse)
  return(d_wide)
}
```


```{r}
fit_irt = function(d_wide) {
  irt_rasch = rasch(d_wide[, 2:ncol(d_wide)], IRT.param = T)
  # Model parameter estimates
  est_difficulty = summary(irt_rasch)$coefficients[1:n_item, 1]
  score.dat = factor.scores(irt_rasch)$score.dat
  resp_score = score.dat$z1
  resp_pat = sapply(seq_along(resp_score), 
                    function(i) paste(score.dat[i, 1:n_item], collapse=""))
  get_subj_ability = function(subj_id) {
    resp = paste(d_wide[subj_id, 2:ncol(d_wide)], collapse = "")
    resp_score[resp_pat == resp]
  }
  est_ability = sapply(1:n_subj, function(id) get_subj_ability(id))
  return(list(
    theta = est_ability,
    delta = est_difficulty
  ))
}
```

### Test Convergence: replicate 100 times with same parameters

```{r}
theta = rnorm(n = n_subj, mean = 0, sd = 1)  # Subjects' ability
delta = rnorm(n = n_item, mean = 0, sd = 1)  # Items' difficulty
```

```{r}
replicate = 100

est_theta = vector("list", replicate)  # Subjects' ability
est_delta = vector("list", replicate)  # Items' difficulty
for (i in 1:replicate) {
  d_wide = dgm(theta, delta)
  est = fit_irt(d_wide)
  est_theta[[i]] = est$theta
  est_delta[[i]] = est$delta
}
```


```{r}
est_theta_mat = sapply(est_theta, function(x) x) |> t()
est_delta_mat = sapply(est_delta, function(x) x) |> t()
```

#### Estimation of Subject Ability

```{r}
d_est_theta = t(est_theta_mat) %>%
  as.data.frame() %>%
  mutate(subj = 1:n_subj) %>%
  pivot_longer(cols = starts_with("V"), values_to = "theta", 
               names_to = "replicate")

est_theta_mean = apply(est_theta_mat, MARGIN = 2, function(col) mean(col))
plot(theta[d_est_theta$subj], d_est_theta$theta)
points(theta, est_theta_mean, col="red", pch=19)
abline(0, 1, col="red")
```

#### Estimation of Item Difficulty

```{r}
d_est_delta = t(est_delta_mat) %>%
  as.data.frame() %>%
  mutate(item = 1:n_item) %>%
  pivot_longer(cols = starts_with("V"), values_to = "delta", 
               names_to = "replicate")

est_delta_mean = apply(est_delta_mat, MARGIN = 2, function(col) mean(col))
plot(delta[d_est_delta$item], d_est_delta$delta)
points(delta, est_delta_mean, col="red", pch=19)
abline(0, 1, col="red")
```



